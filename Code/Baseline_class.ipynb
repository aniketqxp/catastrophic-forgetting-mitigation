{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebe5c90-86a5-47af-8faf-4f3e47ff62cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdf0213c-0647-4577-8d86-d3cf92c402a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Class Incremental MNIST Dataset\n",
    "class ClassIncrementalMNIST(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, classes=None):\n",
    "        self.mnist_dataset = torchvision.datasets.MNIST(root=root, train=train, transform=transforms.ToTensor(), download=True)\n",
    "        self.transform = transform\n",
    "        self.classes = classes\n",
    "        self.train = train\n",
    "        # Filter data to include only the specified classes\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        for image, label in self.mnist_dataset:\n",
    "            if label in self.classes:\n",
    "                self.data.append(image)\n",
    "                self.targets.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.data[idx], self.targets[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Setup Class Incremental MNIST Tasks\n",
    "num_tasks = 5\n",
    "classes_per_task = 2\n",
    "\n",
    "# Divide classes into tasks\n",
    "class_splits = [list(range(i * classes_per_task, (i + 1) * classes_per_task)) for i in range(num_tasks)]\n",
    "\n",
    "# Load datasets for each task\n",
    "train_tasks = [ClassIncrementalMNIST(root=\"./data\", train=True, classes=class_splits[i]) for i in range(num_tasks)]\n",
    "test_tasks = [ClassIncrementalMNIST(root=\"./data\", train=False, classes=class_splits[i]) for i in range(num_tasks)]\n",
    "\n",
    "# Function to create DataLoaders\n",
    "def get_task_data(task_idx, batch_size=64):\n",
    "    train_loader = DataLoader(train_tasks[task_idx], batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_tasks[task_idx], batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dea907ad-c04c-4908-8e59-e285050b6f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SimpleNN model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Train function with improved monitoring\n",
    "def train_task(model, task_idx, criterion, optimizer, epochs=5):\n",
    "    train_loader, _ = get_task_data(task_idx)\n",
    "    \n",
    "    # For collecting metrics\n",
    "    task_train_loss = []\n",
    "    task_train_acc = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        \n",
    "        task_train_loss.append(epoch_loss)\n",
    "        task_train_acc.append(epoch_acc)\n",
    "        \n",
    "        print(f'Task {task_idx+1}, Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "    \n",
    "    return task_train_loss, task_train_acc\n",
    "\n",
    "# Evaluate function for cumulative classes\n",
    "def evaluate_cumulative_classes(model, num_tasks):\n",
    "    combined_test_set = ConcatDataset(test_tasks[:num_tasks])\n",
    "    test_loader = DataLoader(combined_test_set, batch_size=64, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Baseline continual learning demonstration\n",
    "def demonstrate_baseline():\n",
    "    input_size = 28 * 28\n",
    "    hidden_size = 256\n",
    "    learning_rate = 0.01\n",
    "    epochs_per_task = 5\n",
    "    \n",
    "    # Start with output size for first task\n",
    "    output_size = 10  # All MNIST digits (0-9)\n",
    "    \n",
    "    model = SimpleNN(input_size, hidden_size, output_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    for task_idx in range(len(class_splits)):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training on Task {task_idx+1}: Classes {class_splits[task_idx]}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        train_loss, train_acc = train_task(model, task_idx, criterion, optimizer, epochs_per_task)\n",
    "        \n",
    "        accuracy = evaluate_cumulative_classes(model, task_idx + 1)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        print(f\"\\nModel Accuracy after Task {task_idx + 1}: {accuracy:.2f}%\")\n",
    "    \n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04228ace-8992-471c-8f7a-a5d8a9c53ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training on Task 1: Classes [0, 1]\n",
      "==================================================\n",
      "Task 1, Epoch 1/5, Loss: 0.4350, Accuracy: 97.81%\n",
      "Task 1, Epoch 2/5, Loss: 0.0369, Accuracy: 99.68%\n",
      "Task 1, Epoch 3/5, Loss: 0.0216, Accuracy: 99.73%\n",
      "Task 1, Epoch 4/5, Loss: 0.0162, Accuracy: 99.76%\n",
      "Task 1, Epoch 5/5, Loss: 0.0133, Accuracy: 99.76%\n",
      "\n",
      "Model Accuracy after Task 1: 99.91%\n",
      "\n",
      "==================================================\n",
      "Training on Task 2: Classes [2, 3]\n",
      "==================================================\n",
      "Task 2, Epoch 1/5, Loss: 0.6992, Accuracy: 84.71%\n",
      "Task 2, Epoch 2/5, Loss: 0.1569, Accuracy: 95.57%\n",
      "Task 2, Epoch 3/5, Loss: 0.1226, Accuracy: 96.23%\n",
      "Task 2, Epoch 4/5, Loss: 0.1084, Accuracy: 96.54%\n",
      "Task 2, Epoch 5/5, Loss: 0.1006, Accuracy: 96.81%\n",
      "\n",
      "Model Accuracy after Task 2: 47.82%\n",
      "\n",
      "==================================================\n",
      "Training on Task 3: Classes [4, 5]\n",
      "==================================================\n",
      "Task 3, Epoch 1/5, Loss: 0.7628, Accuracy: 82.77%\n",
      "Task 3, Epoch 2/5, Loss: 0.1339, Accuracy: 97.26%\n",
      "Task 3, Epoch 3/5, Loss: 0.0865, Accuracy: 98.04%\n",
      "Task 3, Epoch 4/5, Loss: 0.0676, Accuracy: 98.38%\n",
      "Task 3, Epoch 5/5, Loss: 0.0575, Accuracy: 98.54%\n",
      "\n",
      "Model Accuracy after Task 3: 30.72%\n",
      "\n",
      "==================================================\n",
      "Training on Task 4: Classes [6, 7]\n",
      "==================================================\n",
      "Task 4, Epoch 1/5, Loss: 0.6070, Accuracy: 89.70%\n",
      "Task 4, Epoch 2/5, Loss: 0.0513, Accuracy: 99.66%\n",
      "Task 4, Epoch 3/5, Loss: 0.0306, Accuracy: 99.73%\n",
      "Task 4, Epoch 4/5, Loss: 0.0229, Accuracy: 99.76%\n",
      "Task 4, Epoch 5/5, Loss: 0.0186, Accuracy: 99.76%\n",
      "\n",
      "Model Accuracy after Task 4: 24.64%\n",
      "\n",
      "==================================================\n",
      "Training on Task 5: Classes [8, 9]\n",
      "==================================================\n",
      "Task 5, Epoch 1/5, Loss: 0.6748, Accuracy: 86.90%\n",
      "Task 5, Epoch 2/5, Loss: 0.1368, Accuracy: 96.31%\n",
      "Task 5, Epoch 3/5, Loss: 0.1071, Accuracy: 96.74%\n",
      "Task 5, Epoch 4/5, Loss: 0.0928, Accuracy: 97.06%\n",
      "Task 5, Epoch 5/5, Loss: 0.0839, Accuracy: 97.31%\n",
      "\n",
      "Model Accuracy after Task 5: 19.25%\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    accuracies = demonstrate_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924e99d-e245-42de-b9cf-4c13e1b54cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
